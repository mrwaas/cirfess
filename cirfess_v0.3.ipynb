{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Motif Coverage Predictor\n",
    "\n",
    "This program is designed to return the number of peptides for a protein (or set of proteins) which contain a given sequence motif (N-glyco motif) and are suitable for mass spectrometry. \n",
    "\n",
    "The program considers protein-level information from prediction tools such as `TMHMM`, `Phobius`, and `SignalP` in order to better interpret the context of possible sequence motifs. \n",
    "\n",
    "## I/O and Usage\n",
    "\n",
    "### Usage\n",
    "\n",
    "### Input\n",
    "\n",
    "\n",
    "### Output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains the definitions of functions to parse the various input file types, including:\n",
    "    # TMHMM short format output\n",
    "    # Phobius short format output\n",
    "    # Signal P short format output\n",
    "    # Fasta file\n",
    "\n",
    "# \n",
    "\n",
    "# Dependencies\n",
    "    # regular expressions (re)\n",
    "\n",
    "\n",
    "\n",
    "def parse_TMHMM(file_name):\n",
    "    import re\n",
    "    with open(file_name, 'r') as fo:\n",
    "        tm_dict = dict()\n",
    "        for line in fo:\n",
    "            line = line.rstrip()\n",
    "            ID = line.split('\\t')[0]\n",
    "            length = int(line.split('\\t')[1].split('=')[1])\n",
    "            topo_str = line.split('\\t')[5].split('=')[1]\n",
    "            num_TM = int(line.split('\\t')[4].split('=')[1])\n",
    "            \n",
    "            if len(topo_str) == 1:\n",
    "                tm_dict[ID] = { 'length' : length, 'num_TM' : num_TM , 'topo' : 'n/a' }\n",
    "            else:\n",
    "                tm_dict[ID] = { 'length' : length, 'num_TM' : num_TM , 'topo' : topo_str } \n",
    "                \n",
    "        \n",
    "        for key in tm_dict:\n",
    "            inside = list()\n",
    "            outside = list()\n",
    "            i1 = list()\n",
    "            i2 = list()\n",
    "            o1 = list()\n",
    "            o2 = list()\n",
    "            \n",
    "            topo = tm_dict[key]['topo']\n",
    "            \n",
    "            if topo:\n",
    "                \n",
    "                if topo.startswith('i'):\n",
    "                   i1.append(1)\n",
    "                elif topo.startswith('o'):\n",
    "                   o1.append(1)\n",
    "                    \n",
    "                for match in re.finditer(r'i(\\d+?)-(\\d+?)o', topo):\n",
    "                    i2.append(int(match.group(1))-1)\n",
    "                    o1.append(int(match.group(2))+1)\n",
    "                for match in re.finditer(r'o(\\d+?)-(\\d+?)i', topo):\n",
    "                    i1.append(int(match.group(2))+1)\n",
    "                    o2.append(int(match.group(1))-1)\n",
    "        \n",
    "                if len(i1) > len(i2):\n",
    "                    i2.append(tm_dict[key]['length'])\n",
    "                elif len(o1) > len(o2):\n",
    "                    o2.append(tm_dict[key]['length'])\n",
    "             \n",
    "            inside_residues = list()\n",
    "            outside_residues = list()\n",
    "            \n",
    "            for i in range(len(i1)):\n",
    "                inside_residues.extend(list(range(i1[i],i2[i]+1)))\n",
    "                \n",
    "            for i in range(len(o1)):\n",
    "                outside_residues.extend(list(range(o1[i],o2[i]+1)))\n",
    "                \n",
    "            tm_dict[key]['inside'] = inside_residues\n",
    "            tm_dict[key]['outside'] = outside_residues\n",
    "            \n",
    "                    \n",
    "    return tm_dict\n",
    "\n",
    "def parse_Phobius(file_name):\n",
    "    import re\n",
    "    with open(file_name, 'r') as fo:\n",
    "        \n",
    "        tm_dict = dict()\n",
    "        \n",
    "        with open('io_files/human_plus_leftovers.tab' , 'r') as fo2:\n",
    "            length_dict = dict()\n",
    "            header = True\n",
    "            for line in fo2:\n",
    "                if header:\n",
    "                    header = False\n",
    "                else:\n",
    "                    line = line.rstrip()\n",
    "                    ID = line.split()[0]\n",
    "                    length = line.split('\\t')[6]\n",
    "                    length_dict[ID] = int(length)\n",
    "                            \n",
    "        for line in fo:\n",
    "            line = line.rstrip()\n",
    "            ID, num_TM, SP, topo_str = line.split()\n",
    "            ID = ID.split('|')[1]\n",
    "            \n",
    "            if bool(length_dict.get(ID)):\n",
    "                length = length_dict[ID]\n",
    "            else:\n",
    "                continue   \n",
    "            \n",
    "            if len(topo_str) < 1:\n",
    "                tm_dict[ID] = { 'length' : length, 'topo' : 'n/a' , \\\n",
    "                                'num_TM' : int(num_TM), 'SP' : SP}\n",
    "            else:\n",
    "                tm_dict[ID] = { 'length' : length, 'topo' : topo_str ,  \\\n",
    "                                'num_TM' : int(num_TM), 'SP' : SP}\n",
    "                \n",
    "        for key in tm_dict:\n",
    "            inside = list()\n",
    "            outside = list()\n",
    "            i1 = list()\n",
    "            i2 = list()\n",
    "            o1 = list()\n",
    "            o2 = list()\n",
    "            \n",
    "            topo = tm_dict[key]['topo']\n",
    "            \n",
    "            if topo:\n",
    "                \n",
    "                if topo.startswith('i'):\n",
    "                    i1.append(1)\n",
    "                elif topo.startswith('o'):\n",
    "                    o1.append(1)\n",
    "                else:\n",
    "                    match = re.search(r'\\S+/(\\S+?)([io])(\\S*)', topo)\n",
    "                    if match:\n",
    "                        topo = match.group(2) + match.group(3)\n",
    "                    else:\n",
    "                        print(topo)\n",
    "                    if topo.startswith('i'):\n",
    "                        i1.append(int(match.group(1)))\n",
    "                    elif topo.startswith('o'):\n",
    "                        o1.append(int(match.group(1)))\n",
    "                   \n",
    "                   \n",
    "                    \n",
    "                for match in re.finditer(r'i(\\d+?)-(\\d+?)o', topo):\n",
    "                    i2.append(int(match.group(1))-1)\n",
    "                    o1.append(int(match.group(2))+1)\n",
    "                for match in re.finditer(r'o(\\d+?)-(\\d+?)i', topo):\n",
    "                    i1.append(int(match.group(2))+1)\n",
    "                    o2.append(int(match.group(1))-1)\n",
    "        \n",
    "                if len(i1) > len(i2):\n",
    "                    i2.append(tm_dict[key]['length'])\n",
    "                elif len(o1) > len(o2):\n",
    "                    o2.append(tm_dict[key]['length'])\n",
    "             \n",
    "            inside_residues = list()\n",
    "            outside_residues = list()\n",
    "            \n",
    "            for i in range(len(i1)):\n",
    "                inside_residues.extend(list(range(i1[i],i2[i]+1)))\n",
    "                \n",
    "            for i in range(len(o1)):\n",
    "                outside_residues.extend(list(range(o1[i],o2[i]+1)))\n",
    "                \n",
    "            tm_dict[key]['inside'] = inside_residues\n",
    "            tm_dict[key]['outside'] = outside_residues\n",
    "            \n",
    "    return tm_dict\n",
    "\n",
    "\n",
    "def parse_signalP(file_name):\n",
    "    \n",
    "        with open(file_name, 'r') as fo:\n",
    "            \n",
    "            SP_dict = dict()\n",
    "            \n",
    "            for line in fo:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                else:\n",
    "                    line = line.rstrip()\n",
    "                    ID = line.split()[0]\n",
    "                    SP = line.split()[1]\n",
    "                    score = line.split()[2]\n",
    "                    \n",
    "                    if SP.startswith('SP'):\n",
    "                        SP = 'Y'\n",
    "                    else:\n",
    "                        SP = 0\n",
    "            \n",
    "                    SP_dict[ID] = { 'SP': SP , 'score' : score } \n",
    "        \n",
    "        return SP_dict\n",
    "    \n",
    "def parse_Predisi(file_name):\n",
    "    \n",
    "    with open (file_name, 'r') as fo:\n",
    "        \n",
    "        predisi_dict = dict()\n",
    "        header = True\n",
    "        \n",
    "        for line in fo:\n",
    "            if header:\n",
    "                header = False\n",
    "            else:\n",
    "                line = line.rstrip()\n",
    "                ID = line.split('\\t')[0].split('|')[1]\n",
    "                SP = line.split('\\t')[-2]\n",
    "                score  = line.split('\\t')[-4]\n",
    "                \n",
    "                predisi_dict[ID] = {'SP' : SP, 'score' : score}\n",
    "                \n",
    "                \n",
    "    return predisi_dict\n",
    "    \n",
    "def parse_SPC(seq_dict, file_name):\n",
    "    \n",
    "    with open(file_name, 'r') as fo:\n",
    "        \n",
    "            SPC_dict = dict()\n",
    "            header = True\n",
    "\n",
    "            for line in fo:\n",
    "                    if header:\n",
    "                        header = False\n",
    "                    else:\n",
    "                        line = line.rstrip()\n",
    "                        ID, SPC, BF, T, dC, DR = line.split(',') \n",
    "                        \n",
    "                        SPC_dict[ID] = dict() \n",
    "                        SPC_dict[ID]['score'] = int(SPC)\n",
    "                        \n",
    "                        stringOut = ''\n",
    "                        \n",
    "                        if int(BF) == 1 :\n",
    "                            stringOut += 'BF'\n",
    "                        if int(T) == 1 :\n",
    "                            stringOut += ',T'\n",
    "                        if int(dC) == 1:\n",
    "                            stringOut += ',dC'\n",
    "                        if int(DR) == 1:\n",
    "                            stringOut += ',DR'\n",
    "                        \n",
    "                        stringOut = stringOut.lstrip(',')                            \n",
    "                        \n",
    "                        SPC_dict[ID]['stringOut'] = stringOut\n",
    "            \n",
    "            for ID in seq_dict:\n",
    "                \n",
    "                if SPC_dict.get(ID) == None:\n",
    "                    SPC_dict[ID] = {'score': 0, 'stringOut' : 'n/a'}\n",
    "            \n",
    "    return SPC_dict\n",
    "        \n",
    "        \n",
    "            \n",
    "def fasta_parser(fasta_filename):   \n",
    "    \n",
    "\n",
    "    fasta_fileobj = open(fasta_filename, 'r')\t## create a file obj from the specified file\n",
    "\n",
    "    sequence_name = ''\t\t\t\t## initialize strings to populate from file object info\n",
    "    sequence_desc = ''\n",
    "    sequence_string = ''\n",
    "    sequence_dict = {}\n",
    "\n",
    "    for line in fasta_fileobj:  \t\t\t## iterate through file object with for loop\n",
    "        line = line.rstrip()\t\t\t## strip white space on the right side (like a new line character!) \n",
    "\n",
    "        if line.startswith('>'):\n",
    "            \n",
    "            if len(sequence_string) > 0:\n",
    "                sequence_dict[sequence_name] = sequence_string\t\n",
    "                sequence_string = ''  \t\t## reset for the new sequence\n",
    "            \n",
    "            line = line.lstrip('>')  \t\t## remove leading `>` char\n",
    "            sequence_info = line.split(maxsplit=1)  ## split on only first space\n",
    "            sequence_name = sequence_info[0].split('|')[1]\n",
    "\t\n",
    "            if len(sequence_info) > 1:\n",
    "                sequence_desc = sequence_info[1]\n",
    "            else:\t\t\t\t\t## sequence has no description, set to empty\n",
    "                sequence_desc = ''\n",
    "\t\t\n",
    "           \n",
    "            line = line.lstrip('>')  \t\t## remove leading `>` char\n",
    "            sequence_info = line.split(maxsplit=1)  \t## split on only first space\n",
    "           \n",
    "            if len(sequence_info) > 1:\n",
    "                sequence_desc = sequence_info[1]\n",
    "           \n",
    "            else:\n",
    "            # sequence has no description, set to empty\n",
    "                sequence_desc = ''\n",
    "             \n",
    "        else:\n",
    "            sequence_string += line  # incrementally elongate seq\n",
    "\n",
    "# When we reach the end of the FASTA file, we drop out of the\n",
    "# 'for' loop. However, we still have the last sequence record\n",
    "# stored in memory, which we haven't processed yet, because we\n",
    "# haven't observed a '>' symbol, so we must copy and paste any\n",
    "# code that we used to process sequences above to the code block\n",
    "# below. Check if sequence_string has a non-zero length to\n",
    "# determine whether to execute the sequence processing code:\n",
    "\n",
    "    if len(sequence_string) > 0:\n",
    "        sequence_dict[sequence_name] = sequence_string\n",
    "        \n",
    "    return sequence_dict\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contatins the definition of functions required \n",
    "\n",
    "import re\n",
    "\n",
    "## 2 missed cleavages are used for trypsinize, where the number of missed cleavages are recorded\n",
    "\n",
    "def trypsinize(prot_seq):\n",
    "    peptides= []\n",
    "    cut_sites=[0]\n",
    "    indices = []\n",
    "    pep = ''\n",
    "\n",
    "    for i in range(0,len(prot_seq)-1):\n",
    "        if prot_seq[i] == 'K' and prot_seq[i+1] != 'P':\n",
    "            cut_sites.append(i+1)\n",
    "        elif prot_seq[i] == 'R' and prot_seq[i+1] != 'P':\n",
    "            cut_sites.append(i+1)\n",
    "        \n",
    "    if cut_sites[-1]!=len(prot_seq):\n",
    "            cut_sites.append(len(prot_seq))\n",
    "            \n",
    "    if len(cut_sites)>2:\n",
    "            \n",
    "        for j in range(0,len(cut_sites)-3):\n",
    "\n",
    "            pep = prot_seq[cut_sites[j]:cut_sites[j+1]]\n",
    "            for i in range(cut_sites[j],cut_sites[j+1]):\n",
    "                indices.append(i+1)\n",
    "            peptides.append({'seq': pep,'indices': indices, 'missed_cleavages' : 0})\n",
    "            indices = []\n",
    "\n",
    "            pep = prot_seq[cut_sites[j]:cut_sites[j+2]]\n",
    "            for i in range(cut_sites[j],cut_sites[j+2]):\n",
    "                indices.append(i+1)\n",
    "            peptides.append({'seq': pep,'indices': indices, 'missed_cleavages' : 1})\n",
    "            indices = []\n",
    "\n",
    "            pep = prot_seq[cut_sites[j]:cut_sites[j+3]]\n",
    "            for i in range(cut_sites[j],cut_sites[j+3]):\n",
    "                indices.append(i+1)\n",
    "            peptides.append({'seq': pep,'indices': indices, 'missed_cleavages' : 2})\n",
    "            indices = []\n",
    "\n",
    "        pep = prot_seq[cut_sites[-3]:cut_sites[-2]]\n",
    "        for i in range(cut_sites[-3],cut_sites[-2]):\n",
    "            indices.append(i+1)\n",
    "        peptides.append({'seq': pep,'indices': indices, 'missed_cleavages' : 0})\n",
    "        indices = []\n",
    "\n",
    "        pep = prot_seq[cut_sites[-3]:cut_sites[-1]]\n",
    "        for i in range(cut_sites[-3],cut_sites[-1]):\n",
    "            indices.append(i+1)\n",
    "        peptides.append({'seq': pep,'indices': indices, 'missed_cleavages' : 1})\n",
    "        indices = []\n",
    "\n",
    "        pep = prot_seq[cut_sites[-2]:cut_sites[-1]]\n",
    "        for i in range(cut_sites[-2],cut_sites[-1]):\n",
    "            indices.append(i+1)\n",
    "        peptides.append({'seq': pep,'indices': indices, 'missed_cleavages' : 0})\n",
    "        indices = []\n",
    "                    \n",
    "    else: #there is no trypsin site in the protein sequence\n",
    "        peptides.append({'seq' : prot_seq, 'indices' : range(1,len(prot_seq)+1), 'missed_cleavages' : 0})\n",
    "        \n",
    "    return peptides\n",
    "\n",
    "def ion_mim(prot_seq, charge_state):\n",
    "    \n",
    "    mass_table = {\n",
    "            \"A\" : 71.03711,\n",
    "            \"R\" : 156.10111,\n",
    "            \"N\" : 114.04293,\n",
    "            \"D\" : 115.02694,\n",
    "            \"C\" : 103.00919 + 57.02146,\n",
    "            \"E\" : 129.04259,\n",
    "            \"Q\" : 128.05858,\n",
    "            \"G\" : 57.02146,\n",
    "            \"H\" : 137.05891,\n",
    "            \"I\" : 113.08406,\n",
    "            \"L\" : 113.08406,\n",
    "            \"K\" : 128.09496,\n",
    "            \"M\" : 131.04049,\n",
    "            \"F\" : 147.06841,\n",
    "            \"P\" : 97.05276,\n",
    "            \"S\" : 87.03203,\n",
    "            \"T\" : 101.04768,\n",
    "            \"W\" : 186.07931,\n",
    "            \"Y\" : 163.06333,\n",
    "            \"V\" : 99.06841\n",
    "            }\n",
    "    \n",
    "    mass = 0\n",
    "    \n",
    "    for aa in mass_table:\n",
    "        mass += prot_seq.count(aa) * mass_table[aa]\n",
    "    \n",
    "    \n",
    "    ion_mass = mass + (charge_state * 1.007276)\n",
    "    m_z = ion_mass/charge_state\n",
    "    \n",
    "    return m_z\n",
    "\n",
    "\n",
    "def ok_for_MS(pep_list):\n",
    "    \n",
    "    for pep in pep_list:\n",
    "        \n",
    "        pep['okForMS'] = ''\n",
    "        \n",
    "        if len(pep['seq']) > 5 and (ion_mim(pep['seq'], 2) < 2000):\n",
    "            pep['okForMS'] += '2'\n",
    "            \n",
    "        if len(pep['seq']) > 5 and (ion_mim(pep['seq'], 3) < 2000):\n",
    "            pep['okForMS'] += ',3'\n",
    "        \n",
    "        if len(pep['okForMS']) > 0:\n",
    "            pep['okForMS'] = pep['okForMS'].lstrip(',')\n",
    "        else:\n",
    "            pep['okForMS'] = None\n",
    "            \n",
    "    return pep_list      \n",
    "\n",
    "def make_prot_dict(seq_dict, tm_dict, phob_dict, sp_dict, predisi_dict, SPC_dict):\n",
    "    \n",
    "    prot_dict = dict()\n",
    "    \n",
    "    for ID in seq_dict:\n",
    "      \n",
    "      seq = seq_dict[ID]\n",
    "    \n",
    "      if tm_dict.get(ID) and phob_dict.get(ID) and sp_dict.get(ID) and predisi_dict.get(ID):\n",
    "        \n",
    "        \n",
    "        pep_list = trypsinize(seq)\n",
    "        \n",
    "        pep_list = ok_for_MS(pep_list)\n",
    "\n",
    "        \n",
    "        glyco_indices_S = list()\n",
    "        \n",
    "        for match in re.finditer(r'N[^P]S', seq ):\n",
    "            glyco_indices_S.append(match.start()+1)\n",
    "        \n",
    "        glyco_indices_T = list()\n",
    "        \n",
    "        for match in re.finditer(r'N[^P]T', seq ):\n",
    "            glyco_indices_T.append(match.start()+1)    \n",
    "            \n",
    "        glyco_indices_C = list()\n",
    "        \n",
    "        for match in re.finditer(r'N[^P]C', seq ):\n",
    "            glyco_indices_C.append(match.start()+1)   \n",
    "        \n",
    "        glyco_indices_V = list()\n",
    "        \n",
    "        for match in re.finditer(r'N[^P]V', seq ):\n",
    "            glyco_indices_V.append(match.start()+1)\n",
    "            \n",
    "        K_indices = list()\n",
    "        C_indices = list()\n",
    "        \n",
    "        for i in range(0, len(seq)):\n",
    "            if seq[i] == 'K':\n",
    "                K_indices.append(i+1)\n",
    "            elif seq[i] == 'C':\n",
    "                C_indices.append(i+1) \n",
    "                \n",
    "        \n",
    "\n",
    "        \n",
    "        prot_dict[ID] = {                             \n",
    "                            'seq_info' :\n",
    "                              { \n",
    "                                  'seq' : seq , \n",
    "                                  'seq_len' : len(seq) \n",
    "                              } , \n",
    "                             \n",
    "                            'topo' :\n",
    "                              {\n",
    "                                 'TMHMM' :\n",
    "                                    { 'inside' : tm_dict[ID]['inside']  ,\n",
    "                                      'outside' : tm_dict[ID]['outside']  ,\n",
    "                                      'num_TM' : tm_dict[ID]['num_TM'] ,\n",
    "                                      'stringOut' : tm_dict[ID]['topo'] \n",
    "                                    } ,\n",
    "                                  \n",
    "                                 'Phobius' :\n",
    "                                    { 'inside' : phob_dict[ID]['inside']  , \n",
    "                                      'outside' : phob_dict[ID]['outside']  ,\n",
    "                                      'num_TM' : phob_dict[ID]['num_TM']  ,\n",
    "                                      'stringOut' : phob_dict[ID]['topo'] \n",
    "                                    }\n",
    "                              } , \n",
    "                           \n",
    "                            'signal' : \n",
    "                              {\n",
    "                                  'Phobius' : {'SP' : phob_dict[ID]['SP'] , 'score' : 0 } ,\n",
    "                                  'SignalP' : {'SP' : sp_dict[ID]['SP'] , 'score' : sp_dict[ID]['score'] } ,\n",
    "                                  'PrediSi' : {'SP' : predisi_dict[ID]['SP'] , 'score' : predisi_dict[ID]['score'] }\n",
    "                              } , \n",
    "                            \n",
    "                            'SPC' : {'score' : int(SPC_dict[ID]['score']) , 'stringOut' : SPC_dict[ID]['stringOut']}, \n",
    "            \n",
    "                            'peptides' : pep_list, \n",
    "\n",
    "            \n",
    "                            'motif_sites' : \n",
    "                               { \n",
    "                                 'NXS' :\n",
    "                                   { 'all' : glyco_indices_S , 'extracellular' : dict()  } ,\n",
    "                                   \n",
    "                                 'NXT' :\n",
    "                                   { 'all' : glyco_indices_T , 'extracellular' : dict()  } , \n",
    "                                   \n",
    "                                 'NXC' :\n",
    "                                   { 'all' : glyco_indices_C , 'extracellular' : dict()  } ,\n",
    "                                   \n",
    "                                 'NXV' :\n",
    "                                   { 'all' : glyco_indices_V , 'extracellular' : dict()  } , \n",
    "                                   \n",
    "                                 'C' :\n",
    "                                   { 'all' : C_indices , 'extracellular' : dict()  } , \n",
    "                                 \n",
    "                                 'K' :\n",
    "                                   { 'all' : K_indices , 'extracellular' : dict()  } , \n",
    "                                    \n",
    "                               }                          \n",
    "                                           \n",
    "                        }\n",
    "\n",
    "    return prot_dict\n",
    "\n",
    "def EC_analysis(prot):\n",
    "    \n",
    "    motif_list = ['NXS','NXT','NXC','NXV','C','K'] \n",
    "        \n",
    "    for pep in prot['peptides']:\n",
    "\n",
    "        for motif in motif_list:\n",
    "        \n",
    "            pep[motif] = dict()\n",
    "            pep[motif]['extracellular'] = dict()\n",
    "        \n",
    "        for pred in ['TMHMM','Phobius']: \n",
    "            \n",
    "            outside_indices = prot['topo'][pred]['outside']\n",
    "\n",
    "            for motif in motif_list:\n",
    "\n",
    "                motif_indices = prot['motif_sites'][motif]['all']\n",
    "                out_motif = list( set(motif_indices) & set(outside_indices) )\n",
    "\n",
    "                prot['motif_sites'][motif]['extracellular'][pred] = out_motif\n",
    "\n",
    "                all = set(motif_indices) & set(pep['indices'])\n",
    "\n",
    "                if all:    \n",
    "                    pep[motif]['all'] = {'num' : len(all), 'indices' : list(all) }\n",
    "\n",
    "                    out = set(out_motif) & set(pep['indices'])\n",
    "\n",
    "                    if out:\n",
    "                        pep[motif]['extracellular'][pred] = {'num' : len(out), 'indices' : list(out)}\n",
    "                    else:\n",
    "                        pep[motif]['extracellular'][pred] = {'num' : '0', 'indices' : 'n/a' }\n",
    "\n",
    "                else: \n",
    "                    pep[motif]['all'] = {'num' : '0', 'indices' : 'n/a' }\n",
    "                    pep[motif]['extracellular'][pred] = {'num' : '0', 'indices' : 'n/a' }\n",
    "                            \n",
    "\n",
    "    return prot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequnces: 20416\n",
      "SignalP: 20413\n",
      "TMHMM: 20412\n",
      "Phobius: 20412\n",
      "SPC: 20424\n",
      "Predisi: 20416\n"
     ]
    }
   ],
   "source": [
    "file_name = 'can_uniprot-proteome_UP000005640+reviewed_yes.fasta'\n",
    "path = 'io_files/'\n",
    "\n",
    "seqs_dict = fasta_parser(path + file_name)\n",
    "print('sequnces:',len(seqs_dict))\n",
    "\n",
    "sp = parse_signalP(path + 'signalp_out.tsv')\n",
    "print('SignalP:',len(sp))\n",
    "\n",
    "TMHMM_dict  = parse_TMHMM(path + 'TMHMM_out_clean.tsv')\n",
    "print('TMHMM:',len(TMHMM_dict))\n",
    "\n",
    "Phobius_dict = parse_Phobius(path + 'Phobius_out_clean.tsv')\n",
    "print('Phobius:',len(Phobius_dict))\n",
    "\n",
    "SPC_dict = parse_SPC(seqs_dict, path + 'SPC_by_Source.csv')\n",
    "print('SPC:',len(SPC_dict))\n",
    "\n",
    "predisi_dict = parse_Predisi(path + 'predisi.txt')\n",
    "print('Predisi:',len(predisi_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_dict = make_prot_dict(seqs_dict, TMHMM_dict, Phobius_dict, sp, predisi_dict, SPC_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pepOut.tsv', 'w') as fo:\n",
    "    \n",
    "    header = ''\n",
    "    fo.write(header + '\\n')\n",
    "    \n",
    "    topo_list = ['all', 'Phobius', 'TMHMM']\n",
    "    motif_list = ['NXS','NXT','NXC','NXV','C','K'] \n",
    "        \n",
    "    for ID in prot_dict:\n",
    "\n",
    "        prot_dict[ID] = EC_analysis(prot_dict[ID])\n",
    "\n",
    "        peps = prot_dict[ID]['peptides']\n",
    "\n",
    "        for pep in peps:\n",
    "\n",
    "            out = list()\n",
    "            pep_range = str(pep['indices'][0]) + '-' + str(pep['indices'][-1])\n",
    "            uniq = ID + '_' + pep_range\n",
    "\n",
    "            out.append(uniq)\n",
    "            out.append(pep['seq'])\n",
    "            out.append(ID)\n",
    "            out.append(pep_range)\n",
    "            out.append(str(pep['missed_cleavages']))\n",
    "\n",
    "            if pep['okForMS']:\n",
    "                out.append(pep['okForMS'])\n",
    "            else:\n",
    "                out.append('None')\n",
    "\n",
    "            for topo in topo_list:\n",
    "\n",
    "                for motif in motif_list:\n",
    "                    if pep[motif]: \n",
    "                        if pep[motif].get(topo):\n",
    "                            out.append(str(pep[motif][topo]['num']))\n",
    "                        elif pep[motif]['extracellular'].get(topo):\n",
    "                            out.append(str(pep[motif]['extracellular'][topo]['num']))\n",
    "                    else:\n",
    "                        out.append('0')\n",
    "\n",
    "                for motif in motif_list:\n",
    "                    if pep[motif]:\n",
    "                        if pep[motif].get(topo):\n",
    "                            indices = pep[motif][topo]['indices']\n",
    "                            if indices == 'n/a':\n",
    "                                out.append(indices)\n",
    "                            else:\n",
    "                                out.append(str(sorted(indices)))\n",
    "                        elif pep[motif]['extracellular'].get(topo):\n",
    "                            indices = pep[motif]['extracellular'][topo]['indices']\n",
    "                            if indices == 'n/a':\n",
    "                                out.append(indices)\n",
    "                            else:\n",
    "                                out.append(str(sorted(indices)))\n",
    "                    else:\n",
    "                        out.append('n/a')\n",
    "\n",
    "            fo.write('\\t'.join(out)+'\\n')\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('protOut.tsv', 'w') as fo:\n",
    "    \n",
    "    header = ''\n",
    "    fo.write(header + '\\n')\n",
    "    \n",
    "    motif_list = ['NXS','NXT','NXC','NXV','C','K']\n",
    "    \n",
    "    for ID in prot_dict:\n",
    "        \n",
    "        out = list()     \n",
    "        prot = prot_dict[ID]\n",
    "        \n",
    "        out.append(ID)\n",
    "        \n",
    "        si = prot['seq_info']\n",
    "        out.append(si['seq'])\n",
    "        out.append(str(si['seq_len']))\n",
    "\n",
    "        for meth in ['Phobius', 'TMHMM']:\n",
    "            topo = prot['topo'][meth]\n",
    "                   \n",
    "            out.append(topo['stringOut'])\n",
    "            out.append(str(topo['num_TM']))\n",
    "            out.append(str(len(topo['inside'])))\n",
    "            out.append(str(len(topo['outside'])))\n",
    "        \n",
    "        sppc = 0\n",
    "        for meth in ['Phobius', 'SignalP', 'PrediSi']:\n",
    "            sig = prot['signal'][meth]\n",
    "                   \n",
    "            if sig['SP'] == 'Y':\n",
    "                out.append('Y')\n",
    "                sppc += 1\n",
    "            else:\n",
    "                out.append('N')\n",
    "                   \n",
    "            if meth == 'Phobius':\n",
    "                out.append('n/a')\n",
    "            else:\n",
    "                out.append(str(sig['score']))\n",
    "                \n",
    "        out.append(str(sppc))       \n",
    "        \n",
    "        spc = prot['SPC']\n",
    "        out.append(str(spc['score']))\n",
    "        out.append(spc['stringOut'])      \n",
    "        \n",
    "        prot = EC_analysis(prot)\n",
    "        \n",
    "        ms = prot['motif_sites'] \n",
    "        for loc in ['all', 'Phobius', 'TMHMM']:\n",
    "            for motif in motif_list:\n",
    "                if loc == 'all':\n",
    "                    sites = ms[motif][loc]\n",
    "                else:\n",
    "                    sites = ms[motif]['extracellular'][loc]\n",
    "                \n",
    "                ns = len(sites)\n",
    "                out.append(str(ns))\n",
    "                if ns:\n",
    "                    out.append(str(sorted(sites)))\n",
    "                else:\n",
    "                    out.append('n/a')\n",
    "                \n",
    "        peps = prot['peptides']\n",
    "        \n",
    "        pep0 = 0\n",
    "        pep1 = 0\n",
    "        pep2 = 0\n",
    "        \n",
    "        ok0 = 0\n",
    "        ok1 = 0\n",
    "        ok2 = 0\n",
    "        \n",
    "        counts = {'all' : dict(), 'Phobius': dict(), 'TMHMM' :dict()}\n",
    "        for key in counts:\n",
    "            counts[key] = [dict(), dict(), dict()]\n",
    "\n",
    "            for i in counts[key]:\n",
    "                for motif in motif_list:\n",
    "                    i[motif] = 0\n",
    "            \n",
    "        for pep in peps:\n",
    "            mc = pep['missed_cleavages']\n",
    "            ok = pep['okForMS']\n",
    "            \n",
    "            if mc == 0:\n",
    "                pep0 += 1\n",
    "                pep1 += 1\n",
    "                pep2 += 1\n",
    "                if ok:\n",
    "                    ok0 += 1\n",
    "                    ok1 += 1\n",
    "                    ok2 += 1\n",
    "            \n",
    "            elif mc == 1: \n",
    "                pep1 += 1\n",
    "                pep2 += 1\n",
    "                if ok:\n",
    "                    ok1 += 1\n",
    "                    ok2 += 1\n",
    "                                   \n",
    "            else:\n",
    "                pep2 += 1\n",
    "                if ok:\n",
    "                    ok2 += 1\n",
    "                    \n",
    "            if ok:\n",
    "                for motif in motif_list:\n",
    "                    for loc in ['all', 'Phobius', 'TMHMM']: \n",
    "                        if loc == 'all':\n",
    "                            if int(pep[motif][loc]['num']) > 0:\n",
    "                                counts[loc][mc][motif] += 1\n",
    "                        else:\n",
    "                            if int(pep[motif]['extracellular'][loc]['num']) > 0:\n",
    "                                counts[loc][mc][motif] += 1\n",
    "                                                        \n",
    "        for var in [pep0, pep1, pep2, ok0, ok1, ok2]:\n",
    "            out.append(str(var))\n",
    "            \n",
    "        for loc in ['all', 'Phobius', 'TMHMM']:\n",
    "            \n",
    "            for i in [0,1,2]:\n",
    "                \n",
    "                for motif in motif_list:\n",
    "                    \n",
    "                    if i == 0:\n",
    "                        count = counts[loc][i][motif]\n",
    "                        \n",
    "                    elif i == 1:\n",
    "                        count = counts[loc][i][motif] + counts[loc][0][motif]\n",
    "                                                \n",
    "                    else:\n",
    "                        count = counts[loc][i][motif] + counts[loc][1][motif] + counts[loc][0][motif]\n",
    "                        \n",
    "                    \n",
    "                    out.append(str(count))\n",
    "    \n",
    "                        \n",
    "        \n",
    "        fo.write('\\t'.join(out)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('upsetOut.csv', 'w') as fo:\n",
    "    \n",
    "    fo.write(','.join(['Accession', 'SPC', 'TM', 'SP']) + '\\n')\n",
    "    \n",
    "    for ID in prot_dict:\n",
    "        out = list()\n",
    "        prot = prot_dict[ID]\n",
    "        \n",
    "        out.append(ID)\n",
    "        \n",
    "        if prot['SPC']['score'] > 0:\n",
    "            SPC = 1\n",
    "        else:\n",
    "            SPC = 0\n",
    "            \n",
    "        out.append(str(SPC))\n",
    "        \n",
    "        topo = prot['topo']\n",
    "        if topo['Phobius']['num_TM'] > 0 or topo['TMHMM']['num_TM'] > 0:\n",
    "            TM = 1\n",
    "        else:\n",
    "            TM = 0\n",
    "            \n",
    "        out.append(str(TM))\n",
    "        \n",
    "        sig = prot['signal']\n",
    "        if sig['Phobius']['SP'] == 'Y' or sig['SignalP']['SP'] == 'Y' or sig['PrediSi']['SP'] == 'Y':\n",
    "            SP = 1\n",
    "        else: \n",
    "            SP = 0\n",
    "            \n",
    "        out.append(str(SP))\n",
    "        \n",
    "        fo.write(','.join(out)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '0.067'\n",
    "test = float(test)\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
